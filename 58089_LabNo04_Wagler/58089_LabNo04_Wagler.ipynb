{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "58089_LabNo04_Wagler.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikkuchan/CpE-AIML/blob/main/58089_LabNo04_Wagler/58089_LabNo04_Wagler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3Ki7Eix6HfL"
      },
      "source": [
        "# Topic 4 Lab 2: Multiple Linear Regression\n",
        "$_{\\text{©D.J. Lopez | 2021 | Fundamentals of Machine Learning}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cApvlgu6RXq"
      },
      "source": [
        "Create a class named `MultipleLinearRegression()` wherein it can compute for the linear regression for multiple variables. The class will be required to have the following helper methods:\n",
        "> 1. `correlations(X, y)`\n",
        ">> input: 2 Rank 2 matrices\n",
        ">>\n",
        ">> output: A vector that contains the covariances of each feature to the target. \n",
        "> 3. `train(X, y)`\n",
        ">> input: 2 Rank 2 matrices\n",
        ">>\n",
        ">> output: the weights of the linear regressor. Use least squares method for this part. If the training fails due to the singularity of the matrix, raise a custom error pertaining to autocorrelation.\n",
        "> 4. `predict(x)`\n",
        ">> input: A testing vector. *Note*: this function should only accept vectors.\n",
        ">>\n",
        ">> output: the predicted value. Note: the procedure in solving for the predicted value should be vectorized. Use the concept of matrix multiplication. Do not forget to pad the matrix for the bias term.\n",
        "> 5. `evaluate()`\n",
        ">> input: *none*\n",
        ">>\n",
        ">> output: a `DataFrame` that displays the SST, SSR, SST, MSE, RMSE, R-squared, and the Adjusted R-squared. Note: You should use the `predict()` method here.\n",
        "> 5. `visualize(testX, testY)`\n",
        ">> input: the dataset training sets and their ground truths.\n",
        ">>\n",
        ">> output: a visualization of the linear regressor over the testing dataset. It should be saved as a .jpg file into the running notebook with a dpi of 400."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UUrD4zJ6EVj"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "## No other packages or libraries can be added in this cell"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WzxCuxQ-xqb"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "class MultipleLinearRegression():\n",
        "  \n",
        "  ### Program the required methods\n",
        "  # coding the correlations\n",
        "  def correlations(self,X,y):\n",
        "    corr = np.round(np.corrcoef(X,y,rowvar=False),2)\n",
        "    values = np.reshape(corr,(1,9))\n",
        "    return values[0][-4:-2]\n",
        "  \n",
        "  # coding the train\n",
        "  def train(self,X,y):\n",
        "    X = self._concatenate_ones(X)\n",
        "    theta = np.round(np.linalg.inv(X.transpose().dot(X)).dot(X.transpose()).dot(y),2)\n",
        "    self.theta = theta\n",
        "    return (theta[-2],theta[-1],theta[0])\n",
        "  \n",
        "  def predict(self,X):\n",
        "    X_size = len(X_test)\n",
        "    self.y_hat = np.c_[np.ones((X_size,1)), X_test]\n",
        "    arr = list(range(0,5))\n",
        "    self.preds = np.dot(self.y_hat,self.theta)\n",
        "    return print(\"ŷᵢ = \", self.preds, \"i = \",arr)\n",
        "\n",
        "  ### You may add other helper functions in to make your code cleaner\n",
        "  def __init__(self):\n",
        "    self.model_ = self.train(X,y)\n",
        "\n",
        "  def _concatenate_ones(self,X):\n",
        "    ones = np.ones(shape=X.shape[0]).reshape(-1,1)\n",
        "    return np.concatenate((ones,X),1)\n",
        "\n",
        "  def _reshape_x(self,X):\n",
        "    return X.reshape(-1,1)\n",
        "  \n",
        "  \n",
        "  def evaluate(self): #SST, SSR, SST, MSE, RMSE, R-squared, and the Adjusted R-squared.  \n",
        "    y=y_train.values.reshape(-1,1)\n",
        "    n = len(y)\n",
        "    k = len(X)  \n",
        "    y_hat = self.predict(X_train)\n",
        "    sst = np.sum(np.square(y)-(y.mean()))          #Sum of Squares Total \n",
        "    ssr = np.sum(np.square(self.y_hat-y.mean()))        #Sum of Squares Regression \n",
        "    mse = np.mean(np.square(self.y_hat-y[0:5]))         #Mean of Squared Error \n",
        "    rmse = np.sqrt(mse)                            #Root Mean Squared Error\n",
        "    sse = np.sum(np.square(self.y_hat-y[0:5]))          #Sum of Squares Error\n",
        "    r2 = (1-(sse/sst))                             #R-squared\n",
        "    ar2 = (1-((1-r2)*(n-1)/(n-k-1)))               #Adjusted R-squared\n",
        "    eval = {      'Sum of Squares Total      [SST] ': [sst],\n",
        "                  'Sum of Squares Regression [SSR] ': [ssr],\n",
        "                  'Mean of Squared Error     [MSE] ': [mse],\n",
        "                  'Root Mean Squared Error   [RMSE]': [rmse],\n",
        "                  'R-squared                 [R²]  ': [r2],\n",
        "                  'Adjusted R-squared        [AR²] ': [ar2]}\n",
        "                  \n",
        "    return eval"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RB4i8MI96Ys"
      },
      "source": [
        "### Testing Data\n",
        "### DO NOT DELETE NOR MODIFY THIS CELL\n",
        "### Data can be retrieved from the git repo\n",
        "X = pd.read_csv(\"/content/real_estate_price_size_year.csv\") \n",
        "y = X['price']\n",
        "X = X.drop('price', axis=1)\n",
        "X_train, X_test = X.iloc[0:95], X.iloc[95:]\n",
        "y_train, y_test = y.iloc[0:95], y.iloc[95:]"
      ],
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGY61WiZ-Ze5"
      },
      "source": [
        "## TEST #1 (Max pts: 5)\n",
        "## DO NOT DELETE NOR MODIFY THIS CELL\n",
        "regressor = MultipleLinearRegression()"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKuHQIceA2D0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a841b0-0cb4-4bac-f105-bacb77f656bf"
      },
      "source": [
        "## TEST #2 (Max pts: 10)\n",
        "## DO NOT DELETE NOR MODIFY THIS CELL\n",
        "R = regressor.correlations(X,y)\n",
        "R"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.09, 0.86])"
            ]
          },
          "metadata": {},
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKPsTkB3BQuj"
      },
      "source": [
        "Expected output value:\n",
        "$$R = \\begin{bmatrix}0.09 & 0.86\\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlWF-AQEBnwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac6d985-e5b1-4be1-99b1-09402297b7da"
      },
      "source": [
        "## TEST #3 (Max pts: 15)\n",
        "## DO NOT DELETE NOR MODIFY THIS CELL\n",
        "regressor.train(X,y)\n",
        "regressor.model_"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(227.7, 2916.79, -5772267.02)"
            ]
          },
          "metadata": {},
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpl2Cz9SB6fz"
      },
      "source": [
        "Expected output value:\n",
        "$$\\omega = \\begin{bmatrix}\\omega_1 \\\\ \\omega_2 \\\\ \\omega_0\\end{bmatrix} = \\begin{bmatrix}232.56 \\\\ 3010.09 \\\\ -5964175.03\\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9Q8e7JXC9U7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e5a2eef-328e-4923-f2c4-f215214066c5"
      },
      "source": [
        "## TEST #4 (Max pts: 35)\n",
        "## DO NOT DELETE NOR MODIFY THIS CELL\n",
        "preds = regressor.predict(X_test)\n",
        "preds"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ŷᵢ =  [212753.55  323789.178 421445.295 252680.463 239408.253] i =  [0, 1, 2, 3, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdpaVDV3DBzr"
      },
      "source": [
        "Expected output value:\n",
        "$$\\hat{y}_i = \\begin{bmatrix} 210962.87 \\\\ 324367.17 \\\\ 424013.31 \\\\ 251928.01 \\\\ 238092.94 \\end{bmatrix}, i = \\{0,1,2,3,4\\}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUJuLe9pDArc",
        "outputId": "9c3724d2-4d3e-4962-9ef7-861740b7f889",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TEST #5 (Max pts: 25)\n",
        "## DO NOT DELETE NOR MODIFY THIS CELL\n",
        "model_stats = regressor.evaluate()\n",
        "model_stats"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ŷᵢ =  [212753.55  323789.178 421445.295 252680.463 239408.253] i =  [0, 1, 2, 3, 4]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Adjusted R-squared        [AR²] ': [3.998061413297366],\n",
              " 'Mean of Squared Error     [MSE] ': [110959347707.93648],\n",
              " 'R-squared                 [R²]  ': [0.8086343778746362],\n",
              " 'Root Mean Squared Error   [RMSE]': [333105.6104419985],\n",
              " 'Sum of Squares Regression [SSR] ': [1274406249162.2305],\n",
              " 'Sum of Squares Total      [SST] ': [8697435814927.636]}"
            ]
          },
          "metadata": {},
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7XW0jArDrQs"
      },
      "source": [
        "## TEST #6 (Max pts: 15)\n",
        "## DO NOT DELETE NOR MODIFY THIS CELL\n",
        "regressor.visualize(X_test, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}